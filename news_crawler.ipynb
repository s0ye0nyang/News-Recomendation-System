{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "news_crawler",
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "18T9le65DJdnS53EL-YJYCnvpE6ZdFVHc",
      "authorship_tag": "ABX9TyMOYJ3J3+3C4NPVx3mI1sxN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s0ye0nyang/News-Recomendation-System/blob/main/news_crawler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRU2ojPbH6L9"
      },
      "source": [
        "!pip install Selenium\r\n",
        "\r\n",
        "!apt-get update # to update ubuntu to correctly run apt install\r\n",
        "\r\n",
        "!apt install chromium-chromedriver"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX5rfQNLtrg7"
      },
      "source": [
        "import torch\r\n",
        "from selenium import webdriver\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "chrome_options = webdriver.ChromeOptions()\r\n",
        "\r\n",
        "chrome_options.add_argument('--headless') #내부 창을 띄울 수 없으므로 설정\r\n",
        "\r\n",
        "chrome_options.add_argument('--no-sandbox')\r\n",
        "\r\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\r\n",
        "\r\n",
        "# setup Driver|Chrome : 크롬드라이버를 사용하는 driver 생성\r\n",
        "driver= webdriver.Chrome('chromedriver',options=chrome_options)\r\n",
        "driver.implicitly_wait(3) # 암묵적으로 웹 자원을 (최대) 3초 기다리기\r\n",
        "date = 10\r\n",
        "news_df = pd.DataFrame()\r\n",
        "max_page = 10\r\n",
        "for i in range(3): # categories\r\n",
        "  for page in range(max_page):\r\n",
        "    for j in range(2,10): # news per page\r\n",
        "      URL = f\"https://news.naver.com/main/list.nhn?mode=LSD&mid=sec&sid1=10{i}&date=20201210&page={page}\"\r\n",
        "      driver.get(URL) \r\n",
        "      html = driver.page_source \r\n",
        "      soup = BeautifulSoup(html, 'html.parser')\r\n",
        "      single_news_link = [a['href'] for a in soup.select(f'#main_content > div.list_body.newsflash_body > ul.type06_headline > li:nth-of-type({j}) > dl > dt:nth-of-type(2) > a[href]')]\r\n",
        "      if single_news_link:\r\n",
        "        # print(\"i,j:\",i,j)\r\n",
        "        driver.get(single_news_link[0])\r\n",
        "        html = driver.page_source\r\n",
        "        soup = BeautifulSoup(html, 'html.parser')\r\n",
        "        news_contents = soup.select('#articleBodyContents')[0].get_text().replace('\\n','')\r\n",
        "        news_df = news_df.append({'제목':single_news_link, \r\n",
        "                                  '기사':news_contents},ignore_index=True)\r\n",
        "    \r\n",
        "\r\n",
        "display(news_df)\r\n",
        "  \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAjdbALNvqvR"
      },
      "source": [
        "news_df.to_csv(\"naver_news.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}